---
title: "task2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,include=FALSE)
library(tidyverse)
library(ggplot2)
library(MASS)
library(mvtnorm)
library(dplyr)
library(qrnn)
library(tidyverse)
library(stats)
library(matrixcalc)
library(pracma)
library(ModelMetrics)
library(readxl)
library(ggrepel)
require(survival)
require(quantreg)
require(glmnet)
require(MASS)
require(pROC)
```

## data cleaning

```{r}
df.raw = read.csv("covid19-1.csv")
df = df.raw %>% 
  janitor::clean_names() %>% 
  dplyr::select(country_region, province_state, date, confirmed_cases) %>% 
  filter(confirmed_cases != 0)

# region with confirm case > 20
df_country = df %>% 
  group_by(country_region) %>% 
  summarise(max=max(confirmed_cases)) %>% 
  filter(max > 20)

region_index = as.character(unique(df_country$country_region))

df.region = function(df, region) {
  df.r = df %>% 
    filter(country_region == region) %>% 
    group_by(country_region, date) %>% 
    summarise(cases = sum(confirmed_cases)) %>% 
    mutate(formal_date = as.Date(date, '%m/%d/%Y')) %>% 
    mutate(time = as.numeric(formal_date-min(formal_date)))%>% 
    arrange(time)  %>% 
    dplyr::select(region = country_region, date, time, cases)
  df.r
}

i= 1
df_list=vector("list", length = length(region_index))
while(i < length(region_index)+1){
  df_list[[i]]   = df.region(df, region_index[i])
  i = i+1
}

for (i in 1:length(df_list)){
names(df_list)[i] <- region_index[i]
}

```

```{r}
res = read_csv("./abc_values") %>% 
  dplyr::select(-X1) %>% 
  mutate(
    a_value = round(a_value,0),
    b_value = round(b_value,3),
    c_value = round(c_value,0)
  ) 
all_t=NULL
for(c in 1:length(df_list))
all_t=rbind(all_t,df_list[[c]][nrow(df_list[[c]]),3])



name_list=unlist(res[,1]) %>% as.vector()
a_values=unlist(res[,2]) %>% as.vector()
b_values=unlist(res[,3]) %>% as.vector()
c_values=unlist(res[,4]) %>% as.vector()
a_values[23]=78732
b_values[23]=0.223
c_values[23]=18
res=data.frame(country_region=name_list,a_value=a_values,b_value=b_values,c_value=c_values)

sum((res[,4])<all_t[,1])# total country pass the mid point


names=res[which((res[,4])<all_t[,1]),1]# names of those country

res[which.min(unlist(res[,3])%>% as.vector()),c(1,3)] # name of country who has most flat grouth rate

res[which.max(unlist(res[,3])%>% as.vector()),c(1,3)] # name of country who has greatest grouth rate
```


```{r}
f.logit=function(beta, t){
  a = beta[1]
  b = beta[2]
  c = beta[3]
  return(a/(1+exp(-b*(t-c))))
}
#for(i in 1:length(df_list)){
#dat_ori=df_list[[i]]
#plot(dat_ori$time,dat_ori$cases)
#lines(dat_ori$time,f.logit(unlist(res[i,2:4]) %>%as.vector() ,dat_ori$time))}
```


## predict data 
```{r}
x3_25=read_csv("3.25-4.05/03-25-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom")) %>% mutate(
  days=c(30,63,63,54,30,62)
)

x3_26=read_csv("3.25-4.05/03-26-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))  %>% mutate(
  days=c(30,63,63,54,30,62)+1
)
x3_27=read_csv("3.25-4.05/03-27-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom")) %>% mutate(
  days=c(30,63,63,54,30,62)+2
)
x3_28=read_csv("3.25-4.05/03-28-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>% mutate(
  days=c(30,63,63,54,30,62)+3
)
x3_29=read_csv("3.25-4.05/03-29-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>% mutate(
  days=c(30,63,63,54,30,62)+4
)
x3_30=read_csv("3.25-4.05/03-30-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>%mutate(
  days=c(30,63,63,54,30,62)+5
)
x3_31=read_csv("3.25-4.05/03-31-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>%mutate(
  days=c(30,63,63,54,30,62)+6
)
x4_1=read_csv("3.25-4.05/04-01-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>%mutate(
  days=c(30,63,63,54,30,62)+7
)
x4_2=read_csv("3.25-4.05/04-02-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>%mutate(
  days=c(30,63,63,54,30,62)+8
)
x4_3=read_csv("3.25-4.05/04-03-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>%mutate(
  days=c(30,63,63,54,30,62)+9
)
x4_4=read_csv("3.25-4.05/04-04-2020.csv.txt") %>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>%mutate(
  days=c(30,63,63,54,30,62)+10
)
x4_5=read_csv("3.25-4.05/04-05-2020.csv.txt")%>% 
group_by(Country_Region) %>% summarize(n=sum(Confirmed)) %>% filter(Country_Region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))%>%mutate(
  days=c(30,63,63,54,30,62)+11
)
```


```{r}
all_add=rbind(x3_25,x3_26,x3_27,x3_28,x3_29,x3_30,x3_31,x4_1,x4_2,x4_3,x4_4,x4_5) 
add=split(all_add,all_add$Country_Region)

beta_use=res%>% filter(country_region  %in% c("Afghanistan","Vietnam","China","US","Korea, South","United Kingdom"))
add_1=NULL
MSE=NULL
for(i in 1:length(add)){
  add_1[[i]]=add[[i]] %>% 
    mutate(
      yhat=f.logit(unlist(beta_use[i,2:4]) %>% as.vector(),days),
    )
  y_hat=add_1[[i]]$yhat
  n_obs=add_1[[i]]$n
  MSE=c(MSE,mse(y_hat,n_obs))
}

names(MSE)=c("Afghanistan","China","Korea_South","United_Kingdom","US","Vietnam")
MSE%>%as.data.frame() %>%  knitr::kable()
```



```{r}
res %>% knitr::kable()
```



Plot some country
```{r}
##Afghanistan
data_try=df_list[[1]]
frame=as.tibble(
  x=seq(1,100,by=1)) %>% mutate(
  y=f.logit(unlist(res[1,2:4]) %>% as.vector(),value)
)

ggplot()+geom_line(frame,mapping = aes(x=value,y=y),color='red')+
  geom_point(data_try,mapping = aes(x=time,y=cases))+theme_bw()+labs(title = "Afghanistan predicted curve",x="Days since first case",y="Cumulative cases")+geom_point(add_1[[1]],mapping=aes(x=days,y=n),color="blue")

##Vietnam
data_try1_1=df_list$Vietnam
frame1_1=as.tibble(
  x=seq(1,100,by=1)) %>% mutate(
  y=f.logit(unlist(res[which(region_index=="Vietnam"),2:4]) %>% as.vector(),value)
)

ggplot()+geom_line(frame1_1,mapping = aes(x=value,y=y),color='red')+
  geom_point(data_try1_1,mapping = aes(x=time,y=cases))+theme_bw()+labs(title = "Vietnam predicted curve",x="Days since first case",y="Cumulative cases")+geom_point(add_1[[6]],mapping=aes(x=days,y=n),color="blue")


## UK
data_try1_2=df_list$`United Kingdom`
frame1_2=as.tibble(
  x=seq(1,100,by=1)) %>% mutate(
  y=f.logit(unlist(res[which(region_index=="United Kingdom"),2:4]) %>% as.vector(),value)
)

ggplot()+geom_line(frame1_2,mapping = aes(x=value,y=y),color='red')+
  geom_point(data_try1_2,mapping = aes(x=time,y=cases))+theme_bw()+labs(title = "United Kingdom predicted curve",x="Days since first case",y="Cumulative cases")+geom_point(add_1[[4]],mapping=aes(x=days,y=n),color="blue")

##China

data_try2=df_list$China %>% mutate(
  time=time
)
frame2=as.tibble(
  x=seq(1,200,by=1)) %>% mutate(
  y=f.logit(unlist(res[which(region_index=="China"),2:4]) %>% as.vector(),value)
)

add_1_china=add_1[[2]] %>% mutate(
  days=days
)

ggplot()+geom_line(frame2,mapping = aes(x=value,y=y),color='red')+
  geom_point(data_try2,mapping = aes(x=time,y=cases))+theme_bw()+labs(title = "China predicted curve since first case",x="Days since first case",y="Cumulative cases")+geom_point(add_1_china,mapping=aes(x=days,y=n),color="blue")

## US
data_try3=df_list$US
frame3=as.tibble(
  x=seq(1,200,by=1)) %>% mutate(
  y=f.logit(unlist(res[which(region_index=="US"),2:4]) %>% as.vector(),value)
)

ggplot()+geom_line(frame3,mapping = aes(x=value,y=y),color='red')+
  geom_point(data_try3,mapping = aes(x=time,y=cases))+theme_bw()+labs(title = "US predicted curve since first case",x="Days since first case",y="Cumulative cases")+geom_point(add_1[[5]],mapping=aes(x=days,y=n),color="blue")

##Korea

data_try4=df_list$`Korea, South`
frame4=as.tibble(
  x=seq(1,200,by=1)) %>% mutate(
  y=f.logit(unlist(res[which(region_index=="Korea, South"),2:4]) %>% as.vector(),value)
)

ggplot()+geom_line(frame4,mapping = aes(x=value,y=y),color='red')+
  geom_point(data_try4,mapping = aes(x=time,y=cases))+theme_bw()+labs(title = "South Korea predicted curve since first case",x="Days since first case",y="Cumulative cases")+geom_point(add_1[[3]],mapping=aes(x=days,y=n),color="blue")

```


```{r}
## Train error
#china
y_add_hat=f.logit(unlist(res[which(region_index=="China"),2:4]) %>% as.vector(),data_try2$time)

train_MSE_china=mse(y_add_hat,data_try2$cases)

# AF
y_add_hat_AF=f.logit(unlist(res[which(region_index=="Afghanistan"),2:4]) %>% as.vector(),data_try$time)

train_MSE_AF=mse(y_add_hat_AF,data_try$cases)

# US
y_add_hat_US=f.logit(unlist(res[which(region_index=="US"),2:4]) %>% as.vector(),data_try3$time)

train_MSE_US=mse(y_add_hat_US,data_try3$cases)
#KS
y_add_hat_KS=f.logit(unlist(res[which(region_index=="Korea, South"),2:4]) %>% as.vector(),data_try4$time)

train_MSE_KS=mse(y_add_hat_KS,data_try4$cases)
#uk
y_add_hat_UK=f.logit(unlist(res[which(region_index=="United Kingdom"),2:4]) %>% as.vector(),data_try1_2$time)

train_MSE_UK=mse(y_add_hat_UK,data_try1_2$cases)
#vie
y_add_hat_VI=f.logit(unlist(res[which(region_index=="Vietnam"),2:4]) %>% as.vector(),data_try1_1$time)

train_MSE_VI=mse(y_add_hat_VI,data_try1_1$cases)


train=data.frame(Country=c("Afghanistan","China","Korea_South","United_Kingdom","US","Vietnam"),Train_error=c(train_MSE_AF,train_MSE_china,train_MSE_KS,train_MSE_UK,train_MSE_US,train_MSE_VI))

train %>% knitr::kable()
```



```{r}
# test error
#china
y_add_hat1=f.logit(unlist(res[which(region_index=="China"),2:4]) %>% as.vector(),add_1_china$days)

test_MSE_china=mse(y_add_hat1,add_1_china$n)

# AF
y_add_hat_AF1=f.logit(unlist(res[which(region_index=="Afghanistan"),2:4]) %>% as.vector(),add_1[[1]]$days)

test_MSE_AF=mse(y_add_hat_AF1,add_1[[1]]$n)

# US
y_add_hat_US1=f.logit(unlist(res[which(region_index=="US"),2:4]) %>% as.vector(),add_1[[5]]$days)

test_MSE_US=mse(y_add_hat_US1,add_1[[5]]$n)
#KS
y_add_hat_KS2=f.logit(unlist(res[which(region_index=="Korea, South"),2:4]) %>% as.vector(),add_1[[3]]$days)

test_MSE_KS=mse(y_add_hat_KS2,add_1[[3]]$n)
#uk
y_add_hat_UK2=f.logit(unlist(res[which(region_index=="United Kingdom"),2:4]) %>% as.vector(),add_1[[4]]$days)

test_MSE_UK=mse(y_add_hat_UK2,add_1[[4]]$n)
#vie
y_add_hat_VI2=f.logit(unlist(res[which(region_index=="Vietnam"),2:4]) %>% as.vector(),add_1[[6]]$days)

test_MSE_VI=mse(y_add_hat_VI2,add_1[[6]]$n)


test=data.frame(Country=c("Afghanistan","China","Korea_South","United_Kingdom","US","Vietnam"),Train_error=c(test_MSE_AF,test_MSE_china,test_MSE_KS,test_MSE_UK,test_MSE_US,test_MSE_VI))
```

```{r}
test %>% knitr::kable()
```



## Task2

```{r}
EM = function(data,ncluster){
  data = as.matrix(data) %>% scale()
  n = nrow(data)
  q = ncol(data)
  p_j = rep(1/ncluster,ncluster)
  mu = data[sample(n,ncluster),] %>% as.matrix()
  covmat = diag(ncol(data))
  covlist = list()
  for(i in 1:ncluster){
    covlist[[i]] = covmat
  }

count = 1
while(count <100){     
  mu0 <- mu

  # E-step: Evaluate posterior probability, gamma     
  gamma <- c()     
  for(j in 1:ncluster){       
    gamma2 <- apply(data,1, dmvnorm, mean = mu[j,], sigma = covlist[[j]])       
    gamma <- cbind(gamma, gamma2)     
  }
    
   # M- step: Calculate mu     
  tempmat <- matrix(rep(p_j,n),nrow=n,byrow = T)     
  r <- (gamma * tempmat) / rowSums(gamma * tempmat)     
  mu <- t(r) %*% data / colSums(r)
  

  # M- step: Calculate Sigma and p     
  for(j in 1:ncluster){       
    sigma <- matrix(rep(0,q^2),ncol=q)       
    for(i in 1:n){         
      sigma = sigma + r[i,j] * (data[i,]-mu0[j,]) %*% t(data[i,]-mu0[j,])       }       
    covlist[[j]] <- sigma/sum(r[,j])     }    
  p_j <- colSums(r)/n    
  count = count + 1  }
  
  cluster <- which(r == apply(r, 1, max), arr.ind = T)   
  cluster <- cluster[order(cluster[,1]),]   
  return(list(mu = mu,covlist = covlist, p_j = p_j,cluster = cluster)) }
```

```{r}
em_dat = res %>% dplyr::select(-country_region) 

res2 = EM(em_dat,2)
res3_3=res2$mu %>% 
  as.data.frame()
res3=res2$mu %>% 
  as.data.frame()


clusters = kmeans(em_dat,5)
clusternumbers = as.factor(clusters$cluster)
```


```{r}
library(factoextra)
#fviz_cluster(clusters, data = em_dat,choose.vars=c("a_value","b_value","c_value"))
set.seed(123)


## use wss
fviz_nbclust(em_dat, kmeans, method = "wss",k.max = 15)

## use silhouette
fviz_nbclust(em_dat, kmeans, method = "silhouette",k.max=15)

## use Gap Statistic Method
library(cluster)
set.seed(123)
gap_stat <- clusGap(em_dat, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)
fviz_gap_stat(gap_stat)


## seems 2 cluster would be a better choice

clusters2 = kmeans(em_dat,2)
clusternumbers = as.factor(clusters2$cluster)
```


```{r}
a_mean = mean(res$a_value)
a_sd = sd(res$a_value)
b_mean = mean(res$b_value)
b_sd = sd(res$b_value)
c_mean = mean(res$c_value)
c_sd = sd(res$c_value)
res3 = res3 %>% 
  mutate(
    a_value = a_value*a_sd+a_mean,
    b_value = b_value*b_sd+b_mean,
    c_value = c_value*c_sd+c_mean,
  )
```


```{r}

combine_em=cbind(em_dat,as.data.frame(res2$cluster)) %>% dplyr::select(-row) 
## calculate EM errors
cal_SS=function(data){
  data=split(data,data$col)
  error_a=error_b=error_c=0
  for(c in 1:2){
for(d in 1:nrow(data[[c]])){
 error_a=error_a+(res3[c,1]-data[[c]][d,1])^2
 error_b=error_b+(res3[c,2]-data[[c]][d,2])^2
 error_c=error_c+(res3[c,3]-data[[c]][d,3])^2
 }
  }
return(error=c(error_a,error_b,error_c))  
}

combine_kmean=cbind(em_dat,clusters2$cluster) %>% mutate(col=clusters2$cluster) 

## calculate the kmeans error
cal_SS2=function(data){
  data=split(data,data$col)
  error_a=error_b=error_c=0
  for(c in 1:2){
for(d in 1:nrow(data[[c]])){
 error_a=error_a+(clusters2$centers[c,1]-data[[c]][d,1])^2
 error_b=error_b+(clusters2$centers[c,2]-data[[c]][d,2])^2
 error_c=error_c+(clusters2$centers[c,3]-data[[c]][d,3])^2
 }
  }
return(error=c(error_a,error_b,error_c))  
}


em_error=cal_SS(combine_em)
em_error
kmean_error=cal_SS2(combine_kmean)
kmean_error


```


```{r}
kmeans_data=combine_kmean  %>% rename(cluster=col)
kmeans_data=kmeans_data[,c(1,2,3,5)] %>% mutate(country=region_index) 
split(kmeans_data,kmeans_data$cluster)

```

